{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Train start--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1] :  87%|████████▋ | 173125/200000 [1:31:34<14:12, 31.51it/s]\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_129005/1986890152.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mmatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'match_no'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'win'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{pickle_path}{match_id}.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mwinner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPASTA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0;31m# RawIOBase, BufferedIOBase, TextIOBase, TextIOWrapper, mmap]\";\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0;31m# expected \"IO[bytes]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mexcs_to_catch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;31m# e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import pasta_spaghettini_g3 as spa\n",
    "#import pasta_spaghettini as spa\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "data_route = '../../Dataset/League_of_Legends/features_tensor/'\n",
    "match_list = pd.read_feather('./processed_ftr/match_result_train.ftr')\n",
    "total_rows = match_list.shape[0]\n",
    "\n",
    "model = 1 # 0: time-reversed // 1: time_reversed(bce) // 2: chronological // 3: chronological(bce)\n",
    "\n",
    "if model == 0:\n",
    "    highest_acc = 0.992985\n",
    "    param_path = './parameters/param_spa_g3'\n",
    "    pickle_path = f'{data_route}by_team_train/'\n",
    "    bce = False\n",
    "elif model == 1:\n",
    "    highest_acc = 0.0\n",
    "    param_path = './parameters/param_spa_g3_bce'\n",
    "    pickle_path = f'{data_route}by_team_train/'\n",
    "    bce = True\n",
    "elif model == 2:\n",
    "    highest_acc = 0.990500\n",
    "    param_path = './parameters/param_spa_g3_ch'\n",
    "    pickle_path = f'{data_route}by_team_train_ch/'\n",
    "    bce = False\n",
    "else:\n",
    "    highest_acc = 0.0\n",
    "    param_path = './parameters/param_spa_g3_ch_bce'\n",
    "    pickle_path = f'{data_route}by_team_train_ch/'\n",
    "    bce = True\n",
    "\n",
    "PASTA = spa.PASTA(input_size=30, hidden_size=8, num_layers=2, learning_rate=0.001)\n",
    "PASTA.load_parameter(param_path)\n",
    "\n",
    "print(\"--Train start--\")\n",
    "for epoch in range(10):\n",
    "    confusion_matrix, c_label = [0, 0, 0, 0], [\"TN\", \"FP\", \"FN\", \"TP\"]\n",
    "    match_list = match_list.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    for idx in tqdm(range(total_rows), desc='[Epoch %1d] '%(epoch+1)):\n",
    "        row = match_list.iloc[idx]\n",
    "        match_id, win = row['match_no'], row['win']\n",
    "        features = pd.read_pickle(f\"{pickle_path}{match_id}.pkl\")\n",
    "\n",
    "        winner, predict = PASTA.train(features, win, bce)\n",
    "        correct = 2*winner + predict\n",
    "        confusion_matrix[correct] += 1\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix[0], confusion_matrix[1], confusion_matrix[2], confusion_matrix[3]\n",
    "    acc = (tp+tn)/(tn+fp+fn+tp)\n",
    "    pre = tp/(tp+fp) if (tp+fp) != 0 else 0\n",
    "    rec = tp/(tp+fn) if (tp+fn) != 0 else 0\n",
    "    f1 = 2 * (pre * rec) / (pre + rec)\n",
    "\n",
    "    for idx in range(0, 4):\n",
    "        print(f'{c_label[idx]}: {confusion_matrix[idx]} / ', end='')\n",
    "    print('\\n' + 'Accuracy: %.6f / Precision: %.6f / Recall: %.6f / f1 score: %.6f'%(acc, pre, rec, f1))\n",
    "\n",
    "    if acc > highest_acc:\n",
    "        print(f\"New record. Saving parameters...\\n\")\n",
    "        PASTA.save_parameter(param_path)\n",
    "        highest_acc = acc\n",
    "    else:\n",
    "        print('Save temporary parameters...\\n')\n",
    "        PASTA.save_parameter('./parameters/tmp')\n",
    "    \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pasta_spaghettini_g3 as spa\n",
    "# import pasta_spaghettini as spa\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "data_route = '../../Dataset/League_of_Legends/features_tensor/'\n",
    "match_list = pd.read_feather('./processed_ftr/match_result_test.ftr')\n",
    "total_rows = match_list.shape[0]\n",
    "\n",
    "model = 1 # 0: time-reversed // 1: time_reversed(bce) // 2: chronological // 3: chronological(bce)\n",
    "\n",
    "if model == 0:\n",
    "    highest_acc = 0.992985\n",
    "    param_path = './parameters/param_spa_g3'\n",
    "    pickle_path = f'{data_route}by_team_test/'\n",
    "    bce = False\n",
    "elif model == 1:\n",
    "    highest_acc = 0.0\n",
    "    param_path = './parameters/param_spa_g3_bce'\n",
    "    pickle_path = f'{data_route}by_team_test/'\n",
    "    bce = True\n",
    "elif model == 2:\n",
    "    highest_acc = 0.988595\n",
    "    param_path = './parameters/param_spa_g3_ch'\n",
    "    pickle_path = f'{data_route}by_team_test_ch/'\n",
    "    bce = False\n",
    "else:\n",
    "    highest_acc = 0.0\n",
    "    param_path = './parameters/param_spa_g3_ch_bce'\n",
    "    pickle_path = f'{data_route}by_team_test_ch/'\n",
    "    bce = True\n",
    "\n",
    "PASTA = spa.PASTA(input_size=30, hidden_size=8, num_layers=1, learning_rate=0.01)\n",
    "\n",
    "print(\"--Test start--\")\n",
    "PASTA.load_parameter(param_path)\n",
    "confusion_matrix, c_label = [0, 0, 0, 0], [\"TN\", \"FP\", \"FN\", \"TP\"]\n",
    "\n",
    "for idx in tqdm(range(total_rows), desc='[Epoch %1d] '%(epoch+1)):\n",
    "    row = match_list.iloc[idx]\n",
    "    match_id, win = row['match_no'], row['win']\n",
    "    features = pd.read_pickle(f\"{pickle_path}{match_id}.pkl\")\n",
    "\n",
    "    winner, predict = PASTA.test(features, win, bce)\n",
    "    correct = 2*winner + predict\n",
    "    confusion_matrix[correct] += 1\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix[0], confusion_matrix[1], confusion_matrix[2], confusion_matrix[3]\n",
    "acc = (tp+tn)/(tn+fp+fn+tp) * 100\n",
    "pre = tp/(tp+fp) * 100 if (tp+fp) != 0 else 0\n",
    "rec = tp/(tp+fn) * 100 if (tp+fn) != 0 else 0\n",
    "f1 = 2 * (pre * rec) / (pre + rec)\n",
    "\n",
    "for idx in range(0, 4):\n",
    "    print(f'{c_label[idx]}: {confusion_matrix[idx]} / ', end='')\n",
    "print('\\n' + 'Accuracy: %4.2f / Precision: %.4f / Recall: %.4f / f1 score: %.4f'%(acc, pre, rec, f1))\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
